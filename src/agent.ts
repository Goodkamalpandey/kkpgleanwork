/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import { searchQuery, GleanDoc } from "./gleanClient";
import { OpenAI } from "openai";
import dotenv from "dotenv";
dotenv.config();

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

export async function runAgent(userQuestion: string): Promise<string> {
  const docs: GleanDoc[] = await searchQuery(userQuestion);

  if (docs.length === 0) {
    return `âš ï¸ No results found. This may indicate Glean indexing gaps for your query.`;
  }

  const context = docs.map((d, i) => `Doc ${i + 1} (${d.title || "no title"}):\n${d.snippet || ""}\n`).join("\n---\n");

  const chatRes = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: "You are a smart agent that answers questions from provided context." },
      { role: "user", content: `${context}\n\nQuestion: ${userQuestion}` }
    ]
  });

  return chatRes.choices[0]?.message?.content ?? "ðŸ¤– Error: no response from LLM";
}
